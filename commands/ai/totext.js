// import axios from 'axios';
// import FormData from 'form-data';
// import fs from 'fs';
// import path from 'path';

// // Helper functions
// async function saveMediaToTemp(client, mediaNode, type) {
//   try {
//     const buffer = await client.downloadMediaMessage(mediaNode);
//     if (!buffer || buffer.length === 0) {
//       throw new Error('Empty buffer received');
//     }
    
//     const ext = type === "audio" ? ".mp3" : ".mp4";
//     const fileName = `temp_${Date.now()}${ext}`;
//     const tempDir = process.env.TMPDIR || '/tmp';
//     const filePath = path.join(tempDir, fileName);
    
//     fs.writeFileSync(filePath, buffer);
//     return filePath;
//   } catch (error) {
//     console.error('Save media error:', error.message);
//     throw error;
//   }
// }

// async function uploadToUguu(filePath) {
//   try {
//     const form = new FormData();
//     form.append('file', fs.createReadStream(filePath));
    
//     const { data } = await axios.post('https://uguu.se/upload.php', form, {
//       headers: form.getHeaders(),
//       timeout: 30000
//     });
    
//     if (data.success && data.files && data.files[0]?.url) {
//       return data.files[0].url;
//     }
//     throw new Error('Upload failed: ' + JSON.stringify(data));
//   } catch (error) {
//     console.error('Upload error:', error.message);
//     throw error;
//   }
// }

// export default {
//   name: "totext",
//   aliases: ["transcribe", "speech2text", "audio2text", "whisper", "stt"],
//   category: "ai",
//   description: "Convert audio/video to text using AI transcription",
  
//   async execute(sock, m, args, PREFIX) {
//     const jid = m.key.remoteJid;
    
//     // Extract the quoted message from contextInfo
//     const quotedMessage = m.message?.extendedTextMessage?.contextInfo?.quotedMessage;
    
//     if (!quotedMessage) {
//       return sock.sendMessage(jid, {
//         text: `‚ùå *NO QUOTED MESSAGE DETECTED*\n\n` +
//               `Please reply to an audio message first.\n\n` +
//               `üìå *How to use:*\n` +
//               `1. Receive or send an audio message\n` +
//               `2. Reply to that message with: *${PREFIX}totext*\n\n` +
//               `‚ú® *Example:*\n` +
//               `‚Ä¢ Someone sends you a voice note\n` +
//               `‚Ä¢ You reply: ${PREFIX}totext\n\n` +
//               `‚ö†Ô∏è *Note:* You must reply directly to the audio message.`
//       }, { quoted: m });
//     }
    
//     // Check for audio message
//     let mediaNode = null;
//     let mediaType = null;
    
//     if (quotedMessage.audioMessage) {
//       mediaType = "audio";
//       mediaNode = quotedMessage.audioMessage;
//       console.log('DEBUG - Found audioMessage in quotedMessage');
//     } 
//     else if (quotedMessage.videoMessage) {
//       mediaType = "video";
//       mediaNode = quotedMessage.videoMessage;
//       console.log('DEBUG - Found videoMessage in quotedMessage');
//     }
//     else {
//       return sock.sendMessage(jid, {
//         text: `‚ùå *NO AUDIO/VIDEO FOUND*\n\n` +
//               `The message you replied to doesn't contain audio or video.\n\n` +
//               `üîç *What I found:*\n` +
//               `${Object.keys(quotedMessage).join(', ') || 'Nothing'}\n\n` +
//               `üìå *Please reply to:*\n` +
//               `‚Ä¢ A voice note (üé§ microphone icon)\n` +
//               `‚Ä¢ An audio file\n` +
//               `‚Ä¢ A video with audio`
//       }, { quoted: m });
//     }
    
//     let filePath;
//     try {
//       // Send initial processing message
//       const statusMsg = await sock.sendMessage(jid, {
//         text: `üîÑ *DOWNLOADING AUDIO...*\n\n` +
//               `Preparing audio for transcription...\n` +
//               `‚è≥ Please wait...`
//       }, { quoted: m });
      
//       // Get audio duration if available
//       const duration = mediaNode.seconds ? `${mediaNode.seconds} seconds` : 'Unknown';
//       const fileSize = mediaNode.fileLength ? `${Math.round(mediaNode.fileLength / 1024)} KB` : 'Unknown';
      
//       // Download and save the media
//       filePath = await saveMediaToTemp(sock, mediaNode, mediaType);
      
//       // Update status
//       await sock.sendMessage(jid, {
//         text: `üì§ *UPLOADING TO SERVER...*\n\n` +
//               `Audio Info:\n` +
//               `‚Ä¢ Duration: ${duration}\n` +
//               `‚Ä¢ Size: ${fileSize}\n` +
//               `‚Ä¢ Type: ${mediaType.toUpperCase()}\n\n` +
//               `‚è≥ Uploading...`,
//         edit: statusMsg.key
//       });
      
//       // Upload to uguu.se
//       const mediaUrl = await uploadToUguu(filePath);
      
//       // Update status
//       await sock.sendMessage(jid, {
//         text: `üé§ *TRANSCRIBING WITH AI...*\n\n` +
//               `Processing speech to text...\n` +
//               `‚è≥ This may take a moment...`,
//         edit: statusMsg.key
//       });
      
//       // Call transcription API
//       const apiUrl = `https://apiskeith.vercel.app/ai/transcribe?q=${encodeURIComponent(mediaUrl)}`;
//       console.log('DEBUG - Calling API:', apiUrl);
      
//       const { data: result } = await axios.get(apiUrl, {
//         timeout: 90000 // 90 seconds for longer audio
//       });
      
//       console.log('DEBUG - API Response status:', result?.status);
      
//       if (!result?.status || !result?.result?.text) {
//         throw new Error('No transcription text received from API');
//       }
      
//       const transcription = result.result.text.trim();
      
//       if (!transcription || transcription.length === 0) {
//         throw new Error('Empty transcription received');
//       }
      
//       // Format the transcription
//       const formattedText = transcription
//         .replace(/\s+/g, ' ')
//         .trim()
//         .replace(/([.!?])\s*/g, '$1\n\n');
      
//       // Count statistics
//       const wordCount = formattedText.split(/\s+/).filter(word => word.length > 0).length;
//       const charCount = formattedText.length;
//       const lineCount = formattedText.split('\n').filter(line => line.trim().length > 0).length;
      
//       // Create final response
//       const responseText = `‚úÖ *TRANSCRIPTION COMPLETE*\n\n` +
//                           `üó£Ô∏è *Transcribed Text:*\n${formattedText}\n\n` +
//                           `üìä *Statistics:*\n` +
//                           `‚Ä¢ Words: ${wordCount}\n` +
//                           `‚Ä¢ Characters: ${charCount}\n` +
//                           `‚Ä¢ Lines: ${lineCount}\n` +
//                           `‚Ä¢ Audio Duration: ${duration}\n\n` +
//                           `‚ö° *Powered by AI Speech Recognition*\n` +
//                           `‚ú® *Command:* ${PREFIX}totext`;
      
//       // Send the transcription
//       await sock.sendMessage(jid, {
//         text: responseText
//       }, { quoted: m });
      
//       // Update status to complete
//       await sock.sendMessage(jid, {
//         text: `‚úÖ *PROCESSING COMPLETE!*\n\n` +
//               `Transcription sent successfully.`,
//         edit: statusMsg.key
//       });
      
//       // Send success reaction
//       await sock.sendMessage(jid, {
//         react: { text: '‚úÖ', key: m.key }
//       });
      
//     } catch (error) {
//       console.error('[TOTEXT ERROR]:', error.message);
//       console.error('[TOTEXT ERROR Stack]:', error.stack);
      
//       let errorMessage = `‚ùå *TRANSCRIPTION FAILED*\n\n`;
      
//       if (error.code === 'ETIMEDOUT' || error.message.includes('timeout')) {
//         errorMessage += `‚Ä¢ Request timeout (90s)\n`;
//         errorMessage += `‚Ä¢ Audio might be too long (207s)\n`;
//         errorMessage += `‚Ä¢ Try with shorter audio (< 60s)\n\n`;
//       } 
//       else if (error.message.includes('No transcription') || error.message.includes('Empty transcription')) {
//         errorMessage += `‚Ä¢ No speech detected\n`;
//         errorMessage += `‚Ä¢ Audio might be silent or unclear\n\n`;
//       }
//       else if (error.message.includes('Upload failed')) {
//         errorMessage += `‚Ä¢ Failed to upload to server\n`;
//         errorMessage += `‚Ä¢ Check internet connection\n\n`;
//       }
//       else if (error.message.includes('Empty buffer')) {
//         errorMessage += `‚Ä¢ Failed to download audio\n`;
//         errorMessage += `‚Ä¢ Audio file might be corrupted\n\n`;
//       }
//       else if (error.message.includes('ENOTFOUND')) {
//         errorMessage += `‚Ä¢ Cannot connect to API server\n`;
//         errorMessage += `‚Ä¢ Try again later\n\n`;
//       }
//       else {
//         errorMessage += `‚Ä¢ Error: ${error.message}\n\n`;
//       }
      
//       errorMessage += `üí° *TIPS FOR SUCCESS:*\n`;
//       errorMessage += `‚Ä¢ Use clear audio with minimal background noise\n`;
//       errorMessage += `‚Ä¢ Keep audio under 60 seconds\n`;
//       errorMessage += `‚Ä¢ Speak clearly at normal pace\n`;
//       errorMessage += `‚Ä¢ Ensure good microphone quality\n\n`;
      
//       errorMessage += `üìå *TRY AGAIN:*\n`;
//       errorMessage += `Reply to a shorter audio message with ${PREFIX}totext`;
      
//       await sock.sendMessage(jid, {
//         text: errorMessage
//       }, { quoted: m });
      
//       // Send error reaction
//       await sock.sendMessage(jid, {
//         react: { text: '‚ùå', key: m.key }
//       });
      
//     } finally {
//       // Clean up temporary file
//       if (filePath && fs.existsSync(filePath)) {
//         try {
//           fs.unlinkSync(filePath);
//           console.log('DEBUG - Cleaned up temp file');
//         } catch (cleanupError) {
//           console.log('Cleanup error:', cleanupError.message);
//         }
//       }
//     }
//   }
// };